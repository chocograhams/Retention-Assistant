import streamlit as st
import pandas as pd
import pdfplumber
import pytesseract
import docx2txt
import fitz  # pymupdf
import os
import tempfile
import datetime
from sentence_transformers import SentenceTransformer, util
from PIL import Image
import io
import zipfile
from xml.etree import ElementTree as ET

st.set_page_config(page_title="ğŸ“ Washington Records Retention Assistant")
st.title("ğŸ“ Washington Records Retention Assistant")

# Load embedding model
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_embedding_model()

# Extract retention rules from PDF
def extract_retention_from_pdf(pdf_file):
    rules = []
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            table = page.extract_table()
            if table:
                for row in table[1:]:
                    if row and len(row) >= 3:
                        category = row[0] if row[0] else ""
                        description = row[1] if row[1] else ""
                        retention = row[2] if row[2] else ""
                        rules.append({
                            "category_name": category.strip(),
                            "category_description": description.strip(),
                            "retention_period": retention.strip()
                        })
    return pd.DataFrame(rules)

# Extract text from various file types
def extract_text(uploaded_file):
    if uploaded_file.name.endswith(".pdf"):
        with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
            return "\n".join([page.get_text() for page in doc])
    elif uploaded_file.name.endswith(".docx"):
        text = docx2txt.process(uploaded_file)
        if text.strip():  # If actual text exists
            return text

        # OCR fallback: extract images from .docx and run OCR
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp_path = os.path.join(tmpdir, uploaded_file.name)
            with open(tmp_path, "wb") as f:
                f.write(uploaded_file.read())
            with zipfile.ZipFile(tmp_path, 'r') as zip_ref:
                image_texts = []
                for file in zip_ref.namelist():
                    if file.startswith("word/media/") and file.endswith((".png", ".jpg", ".jpeg")):
                        zip_ref.extract(file, tmpdir)
                        img_path = os.path.join(tmpdir, file)
                        img = Image.open(img_path)
                        image_texts.append(pytesseract.image_to_string(img))
                return "\n".join(image_texts)
    elif uploaded_file.name.endswith(".txt"):
        return uploaded_file.read().decode("utf-8")
    elif uploaded_file.type.startswith("image"):
        image = Image.open(uploaded_file)
        return pytesseract.image_to_string(image)
    else:
        return ""

# Match document text to best retention category
def match_retention(text, rules_df):
    doc_embedding = model.encode(text, convert_to_tensor=True)
    rule_embeddings = model.encode(rules_df['category_description'].tolist(), convert_to_tensor=True)
    similarities = util.cos_sim(doc_embedding, rule_embeddings)[0]
    top_idx = similarities.argmax().item()
    return {
        "category": rules_df.iloc[top_idx]['category_name'],
        "description": rules_df.iloc[top_idx]['category_description'],
        "retention": rules_df.iloc[top_idx]['retention_period'],
        "score": float(similarities[top_idx])
    }

# Confidence level mapping
def get_confidence_level(score):
    if score >= 0.8:
        return "High", "ğŸŸ¢ High (â‰¥ 0.80): Confident match"
    elif score >= 0.6:
        return "Medium", "ğŸŸ¡ Medium (0.60â€“0.79): Reasonable match"
    else:
        return "Low", "ğŸ”´ Low (< 0.60): Needs review"

# Upload and parse retention schedule
retention_file = st.file_uploader("ğŸ“ Upload a Retention Schedule (PDF)", type="pdf")
if retention_file:
    retention_df = extract_retention_from_pdf(retention_file)
    st.success(f"âœ… Retention schedule '{retention_file.name}' loaded with {len(retention_df)} categories.")

    # Upload multiple documents
    uploaded_files = st.file_uploader("ğŸ“„ Upload Documents to Classify (PDF, DOCX, TXT, Images)", type=["pdf", "docx", "txt", "png", "jpg"], accept_multiple_files=True)

    if uploaded_files:
        log_entries = []
        for uploaded_file in uploaded_files:
            with st.expander(f"ğŸ“„ Document: {uploaded_file.name}", expanded=True):
                text = extract_text(uploaded_file)
                if not text.strip():
                    st.warning("âš ï¸ No readable text found.")
                    continue

                match = match_retention(text, retention_df)
                level, definition = get_confidence_level(match['score'])

                st.markdown(f"**Suggested Category**: {match['category']}")
                st.markdown(f"**Retention Period**: {match['retention']}")
                st.markdown(f"**Description**: {match['description']}")
                st.markdown(f"**Confidence Level**: {definition}")
                st.markdown(f"**Schedule Used**: {retention_file.name}")

                confirm_key = f"confirm_{uploaded_file.name}"
                edit_key = f"edit_{uploaded_file.name}"

                col1, col2 = st.columns(2)
                with col1:
                    if st.button("âœ… Confirm", key=confirm_key):
                        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        log_entries.append({
                            "timestamp": timestamp,
                            "document": uploaded_file.name,
                            "predicted_category": match['category'],
                            "predicted_retention": match['retention'],
                            "override_category": match['category'],
                            "override_retention": match['retention'],
                            "confidence_level": level,
                            "confidence_score": match['score'],
                            "retention_schedule": retention_file.name
                        })
                        st.success(f"ğŸ’¾ Confirmed and saved for {uploaded_file.name}")

                with col2:
                    if st.button("âœï¸ Edit", key=edit_key):
                        override_category = st.text_input("Override Category", value=match['category'], key=f"cat_{uploaded_file.name}")
                        override_retention = st.text_input("Override Retention Period", value=match['retention'], key=f"ret_{uploaded_file.name}")
                        if st.button("ğŸ’¾ Save Edits", key=f"save_{uploaded_file.name}"):
                            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            log_entries.append({
                                "timestamp": timestamp,
                                "document": uploaded_file.name,
                                "predicted_category": match['category'],
                                "predicted_retention": match['retention'],
                                "override_category": override_category,
                                "override_retention": override_retention,
                                "confidence_level": level,
                                "confidence_score": match['score'],
                                "retention_schedule": retention_file.name
                            })
                            st.success(f"ğŸ’¾ Edited and saved for {uploaded_file.name}")

        if log_entries:
            log_df = pd.DataFrame(log_entries)
            log_path = "results_log.csv"
            if os.path.exists(log_path):
                existing = pd.read_csv(log_path)
                log_df = pd.concat([existing, log_df], ignore_index=True)
            log_df.to_csv(log_path, index=False)
            st.info(f"ğŸ“ Results saved to {log_path}")

            # Download button
            csv_bytes = log_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="â¬‡ï¸ Download Results as CSV",
                data=csv_bytes,
                file_name="results_log.csv",
                mime="text/csv"
            )
else:
    st.info("ğŸ‘† Please upload a retention schedule to begin.")
